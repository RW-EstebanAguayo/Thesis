{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8250\n",
      "8250\n",
      "success!\n"
     ]
    }
   ],
   "source": [
    "class PIVDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.flow_types = os.listdir(root_dir)\n",
    "        self.num_samples = self.calculate_num_samples()\n",
    "    \n",
    "    def calculate_num_samples(self):\n",
    "        num_samples = 0\n",
    "        for flow_type in self.flow_types:\n",
    "            flow_dir = os.path.join(self.root_dir, flow_type)\n",
    "            file_names = [f for f in os.listdir(flow_dir) if f.endswith(\"_img1.tif\")]\n",
    "            num_samples += len(file_names)\n",
    "        print(num_samples)\n",
    "        return num_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def load_velocity_field(flow_path):\n",
    "        # Use OpenCV to read the .flo file\n",
    "        flow = cv2.readOpticalFlow(flow_path)\n",
    "        # Convert the loaded flow data to a NumPy array\n",
    "        flow = flow[..., 0:2]  # Extract the U and V components\n",
    "        return flow\n",
    "       \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "    # Initialize the flow_type_idx and remaining_idx\n",
    "        flow_type_idx = 0\n",
    "        remaining_idx = idx\n",
    "        \n",
    "        # Iterate through flow types to find the correct one\n",
    "        while flow_type_idx < len(self.flow_types):\n",
    "            num_samples = len(os.listdir(os.path.join(self.root_dir, self.flow_types[flow_type_idx])))\n",
    "            if (remaining_idx < num_samples) :\n",
    "                break  # Found the correct flow type\n",
    "            else:\n",
    "                remaining_idx -= num_samples  # Adjust the remaining index\n",
    "                flow_type_idx += 1\n",
    "        \n",
    "        # Now that we have the correct flow type, proceed to load the data\n",
    "        flow_type = self.flow_types[flow_type_idx]\n",
    "        flow_dir = os.path.join(self.root_dir, flow_type)\n",
    "        file_names = [f for f in os.listdir(flow_dir) if f.endswith(\"_img1.tif\")]\n",
    "        \n",
    "        instance_name = file_names[remaining_idx]  # Use remaining_idx to access the file\n",
    "        img1_path = os.path.join(flow_dir, instance_name)\n",
    "        img2_path = os.path.join(flow_dir, instance_name.replace(\"_img1.tif\", \"_img2.tif\"))\n",
    "        flow_path = os.path.join(flow_dir, instance_name.replace(\"_img1.tif\", \"_flow.flo\"))\n",
    "        \n",
    "        img1 = Image.open(img1_path)\n",
    "        img2 = Image.open(img2_path)\n",
    "        flow = self.load_velocity_field(flow_path)  # Implement a function to load .flo files\n",
    "        \n",
    "        return {\"image_pair\": (img1, img2), \"velocity_field\": flow}\n",
    "\n",
    "\n",
    " # Create an instance of the custom dataset\n",
    "dataset = PIVDataset(root_dir='C:/Users/estal/OneDrive - ROCKWOOL Group/Documents/GD/Thesis/04_Code/src/data/raw/PIV_dataset/PIV-genImages/data')\n",
    "\n",
    "# Create a data loader\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "print(len(dataset))\n",
    "print(\"success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PIVDataset.load_velocity_field() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\estal\\OneDrive - ROCKWOOL Group\\Documents\\GD\\Thesis\\04_Code\\src\\models\\dataset_loader.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/estal/OneDrive%20-%20ROCKWOOL%20Group/Documents/GD/Thesis/04_Code/src/models/dataset_loader.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/estal/OneDrive%20-%20ROCKWOOL%20Group/Documents/GD/Thesis/04_Code/src/models/dataset_loader.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Assuming you have a data loader called 'data_loader' from your PIVDataset\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/estal/OneDrive%20-%20ROCKWOOL%20Group/Documents/GD/Thesis/04_Code/src/models/dataset_loader.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m data_loader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/estal/OneDrive%20-%20ROCKWOOL%20Group/Documents/GD/Thesis/04_Code/src/models/dataset_loader.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     image_pairs \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mimage_pair\u001b[39m\u001b[39m\"\u001b[39m]  \u001b[39m# This should contain a tuple of (img1, img2)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/estal/OneDrive%20-%20ROCKWOOL%20Group/Documents/GD/Thesis/04_Code/src/models/dataset_loader.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     velocity_fields \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mvelocity_field\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\estal\\AppData\\Local\\anaconda3\\envs\\imageP\\envs\\thesis\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\estal\\AppData\\Local\\anaconda3\\envs\\imageP\\envs\\thesis\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\estal\\AppData\\Local\\anaconda3\\envs\\imageP\\envs\\thesis\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\estal\\AppData\\Local\\anaconda3\\envs\\imageP\\envs\\thesis\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mc:\\Users\\estal\\OneDrive - ROCKWOOL Group\\Documents\\GD\\Thesis\\04_Code\\src\\models\\dataset_loader.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/estal/OneDrive%20-%20ROCKWOOL%20Group/Documents/GD/Thesis/04_Code/src/models/dataset_loader.ipynb#W2sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m img1 \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(img1_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/estal/OneDrive%20-%20ROCKWOOL%20Group/Documents/GD/Thesis/04_Code/src/models/dataset_loader.ipynb#W2sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m img2 \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(img2_path)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/estal/OneDrive%20-%20ROCKWOOL%20Group/Documents/GD/Thesis/04_Code/src/models/dataset_loader.ipynb#W2sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m flow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_velocity_field(flow_path)  \u001b[39m# Implement a function to load .flo files\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/estal/OneDrive%20-%20ROCKWOOL%20Group/Documents/GD/Thesis/04_Code/src/models/dataset_loader.ipynb#W2sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mimage_pair\u001b[39m\u001b[39m\"\u001b[39m: (img1, img2), \u001b[39m\"\u001b[39m\u001b[39mvelocity_field\u001b[39m\u001b[39m\"\u001b[39m: flow}\n",
      "\u001b[1;31mTypeError\u001b[0m: PIVDataset.load_velocity_field() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a data loader called 'data_loader' from your PIVDataset\n",
    "for batch in data_loader:\n",
    "    image_pairs = batch[\"image_pair\"]  # This should contain a tuple of (img1, img2)\n",
    "    velocity_fields = batch[\"velocity_field\"]\n",
    "\n",
    "    # Process the first pair in the first batch and then break\n",
    "    img1 = image_pairs[0][0]  # First image in the pair\n",
    "    img2 = image_pairs[0][1]  # Second image in the pair\n",
    "    flow = velocity_fields[0]  # Velocity field\n",
    "\n",
    "    # Convert the PyTorch tensor to a NumPy array for visualization\n",
    "    img1 = img1.numpy().transpose((1, 2, 0))\n",
    "    img2 = img2.numpy().transpose((1, 2, 0))\n",
    "    flow = flow.numpy()\n",
    "\n",
    "    # Visualization of the first image pair and velocity field\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img1)\n",
    "    plt.title('Image 1')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(img2)\n",
    "    plt.title('Image 2')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(np.sqrt(flow[..., 0]**2 + flow[..., 1]**2), cmap='viridis')\n",
    "    plt.title('Velocity Magnitude')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    break  # Exit the loop after processing the first pair\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
